[2024-04-16T00:00:27.732+0000] {processor.py:161} INFO - Started process (PID=48003) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:00:27.733+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:00:27.735+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:00:27.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:00:27.972+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:00:27.987+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:00:27.979+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:00:27.989+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:00:28.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.276 seconds
[2024-04-16T00:00:58.917+0000] {processor.py:161} INFO - Started process (PID=48063) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:00:58.919+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:00:58.920+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:00:58.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:00:59.177+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:00:59.207+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:00:59.190+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:00:59.208+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:00:59.223+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.310 seconds
[2024-04-16T00:01:29.371+0000] {processor.py:161} INFO - Started process (PID=48126) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:01:29.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:01:29.373+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:01:29.373+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:01:29.631+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:01:29.647+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:01:29.641+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:01:29.648+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:01:29.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.295 seconds
[2024-04-16T00:01:59.874+0000] {processor.py:161} INFO - Started process (PID=48183) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:01:59.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:01:59.877+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:01:59.876+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:02:00.168+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:02:00.194+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:02:00.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:02:00.195+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:02:00.210+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.343 seconds
[2024-04-16T00:02:30.453+0000] {processor.py:161} INFO - Started process (PID=48243) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:02:30.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:02:30.458+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:02:30.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:02:30.726+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:02:30.744+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:02:30.734+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:02:30.745+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:02:30.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.310 seconds
[2024-04-16T00:03:01.052+0000] {processor.py:161} INFO - Started process (PID=48302) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:03:01.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:03:01.056+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:03:01.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:03:01.325+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:03:01.338+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:03:01.332+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:03:01.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:03:01.353+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.306 seconds
[2024-04-16T00:03:31.670+0000] {processor.py:161} INFO - Started process (PID=48362) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:03:31.671+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:03:31.672+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:03:31.672+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:03:31.969+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:03:32.022+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:03:32.008+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:03:32.023+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:03:32.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.372 seconds
[2024-04-16T00:04:02.136+0000] {processor.py:161} INFO - Started process (PID=48422) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:04:02.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:04:02.139+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:04:02.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:04:02.553+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:04:02.581+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:04:02.564+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:04:02.584+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:04:02.601+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.470 seconds
[2024-04-16T00:04:32.877+0000] {processor.py:161} INFO - Started process (PID=48482) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:04:32.878+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:04:32.881+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:04:32.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:04:33.135+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:04:33.152+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:04:33.144+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:04:33.153+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:04:33.168+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.295 seconds
[2024-04-16T00:05:03.634+0000] {processor.py:161} INFO - Started process (PID=48542) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:05:03.636+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:05:03.638+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:05:03.638+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:05:03.896+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:05:03.918+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:05:03.903+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:05:03.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:05:03.931+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.301 seconds
[2024-04-16T00:05:34.481+0000] {processor.py:161} INFO - Started process (PID=48602) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:05:34.481+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:05:34.484+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:05:34.483+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:05:34.735+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:05:34.747+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:05:34.741+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:05:34.748+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:05:34.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.286 seconds
[2024-04-16T00:06:04.876+0000] {processor.py:161} INFO - Started process (PID=48665) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:06:04.877+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:06:04.879+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:06:04.878+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:06:05.112+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:06:05.130+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:06:05.122+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:06:05.131+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:06:05.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.272 seconds
[2024-04-16T00:06:35.254+0000] {processor.py:161} INFO - Started process (PID=48727) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:06:35.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:06:35.258+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:06:35.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:06:35.550+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:06:35.584+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:06:35.567+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:06:35.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:06:35.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.355 seconds
[2024-04-16T00:07:06.342+0000] {processor.py:161} INFO - Started process (PID=48786) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:07:06.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:07:06.345+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:07:06.345+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:07:06.600+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:07:06.631+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:07:06.615+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:07:06.632+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:07:06.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.309 seconds
[2024-04-16T00:07:37.017+0000] {processor.py:161} INFO - Started process (PID=48846) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:07:37.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:07:37.019+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:07:37.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:07:37.272+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:07:37.303+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:07:37.284+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:07:37.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:07:37.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.319 seconds
[2024-04-16T00:08:08.266+0000] {processor.py:161} INFO - Started process (PID=48909) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:08:08.267+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:08:08.269+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:08:08.268+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:08:08.495+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:08:08.512+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:08:08.500+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:08:08.513+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:08:08.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.265 seconds
[2024-04-16T00:08:39.259+0000] {processor.py:161} INFO - Started process (PID=48969) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:08:39.261+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:08:39.264+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:08:39.263+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:08:39.554+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:08:39.584+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:08:39.567+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:08:39.585+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:08:39.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.352 seconds
[2024-04-16T00:09:09.746+0000] {processor.py:161} INFO - Started process (PID=49029) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:09:09.749+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:09:09.752+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:09:09.752+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:09:10.040+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:09:10.066+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:09:10.053+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:09:10.067+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:09:10.084+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.342 seconds
[2024-04-16T00:09:40.431+0000] {processor.py:161} INFO - Started process (PID=49089) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:09:40.432+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:09:40.434+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:09:40.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:09:40.658+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:09:40.684+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:09:40.671+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:09:40.684+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:09:40.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.276 seconds
[2024-04-16T00:10:11.235+0000] {processor.py:161} INFO - Started process (PID=49149) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:10:11.237+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:10:11.239+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:10:11.239+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:10:11.522+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:10:11.631+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:10:11.595+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:10:11.634+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:10:11.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.427 seconds
[2024-04-16T00:10:41.882+0000] {processor.py:161} INFO - Started process (PID=49209) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:10:41.883+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:10:41.884+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:10:41.884+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:10:42.126+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:10:42.222+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:10:42.215+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:10:42.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:10:42.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.358 seconds
[2024-04-16T00:11:12.757+0000] {processor.py:161} INFO - Started process (PID=49269) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:11:12.758+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:11:12.760+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:11:12.760+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:11:13.146+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:11:13.158+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:11:13.151+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:11:13.159+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:11:13.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.422 seconds
[2024-04-16T00:11:43.717+0000] {processor.py:161} INFO - Started process (PID=49328) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:11:43.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:11:43.719+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:11:43.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:11:43.976+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:11:43.994+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:11:43.986+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:11:43.995+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:11:44.008+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.295 seconds
[2024-04-16T00:12:14.241+0000] {processor.py:161} INFO - Started process (PID=49388) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:12:14.242+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:12:14.243+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:12:14.243+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:12:14.471+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:12:14.480+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:12:14.476+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:12:14.481+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:12:14.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.258 seconds
[2024-04-16T00:12:45.032+0000] {processor.py:161} INFO - Started process (PID=49447) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:12:45.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:12:45.034+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:12:45.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:12:45.283+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:12:45.304+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:12:45.293+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:12:45.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:12:45.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.294 seconds
[2024-04-16T00:13:15.803+0000] {processor.py:161} INFO - Started process (PID=49507) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:13:15.804+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:13:15.806+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:13:15.806+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:13:16.051+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:13:16.066+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:13:16.059+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:13:16.067+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:13:16.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.282 seconds
[2024-04-16T00:13:46.445+0000] {processor.py:161} INFO - Started process (PID=49567) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:13:46.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:13:46.448+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:13:46.448+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:13:46.693+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:13:46.717+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:13:46.703+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:13:46.718+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:13:46.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.296 seconds
[2024-04-16T00:14:17.216+0000] {processor.py:161} INFO - Started process (PID=49627) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:14:17.217+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:14:17.219+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:14:17.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:14:17.473+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:14:17.483+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:14:17.477+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:14:17.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:14:17.495+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.284 seconds
[2024-04-16T00:14:47.805+0000] {processor.py:161} INFO - Started process (PID=49687) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:14:47.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:14:47.809+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:14:47.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:14:48.056+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:14:48.073+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:14:48.064+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:14:48.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:14:48.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.285 seconds
[2024-04-16T00:15:18.379+0000] {processor.py:161} INFO - Started process (PID=49747) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:15:18.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:15:18.382+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:15:18.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:15:18.612+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:15:18.622+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:15:18.616+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:15:18.623+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:15:18.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.259 seconds
[2024-04-16T00:15:48.917+0000] {processor.py:161} INFO - Started process (PID=49806) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:15:48.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:15:48.919+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:15:48.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:15:49.162+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:15:49.172+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:15:49.167+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:15:49.173+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:15:49.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.275 seconds
[2024-04-16T00:16:19.588+0000] {processor.py:161} INFO - Started process (PID=49866) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:16:19.589+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:16:19.590+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:16:19.590+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:16:19.935+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:16:19.949+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:16:19.942+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:16:19.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:16:19.962+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.379 seconds
[2024-04-16T00:16:50.279+0000] {processor.py:161} INFO - Started process (PID=49926) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:16:50.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:16:50.290+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:16:50.290+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:16:50.632+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:16:50.645+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:16:50.640+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:16:50.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:16:50.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.382 seconds
[2024-04-16T00:17:20.851+0000] {processor.py:161} INFO - Started process (PID=49986) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:17:20.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:17:20.854+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:17:20.853+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:17:21.179+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:17:21.190+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:17:21.184+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:17:21.191+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:17:21.203+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.356 seconds
[2024-04-16T00:17:51.271+0000] {processor.py:161} INFO - Started process (PID=50046) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:17:51.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:17:51.273+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:17:51.273+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:17:51.617+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:17:51.645+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:17:51.629+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:17:51.646+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:17:51.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.395 seconds
[2024-04-16T00:18:21.817+0000] {processor.py:161} INFO - Started process (PID=50107) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:18:21.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:18:21.819+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:18:21.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:18:22.171+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:18:22.188+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:18:22.182+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:18:22.189+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:18:22.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.389 seconds
[2024-04-16T00:18:52.466+0000] {processor.py:161} INFO - Started process (PID=50164) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:18:52.468+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:18:52.473+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:18:52.472+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:18:52.953+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:18:52.981+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:18:52.965+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:18:52.982+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:18:52.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.535 seconds
[2024-04-16T00:19:23.141+0000] {processor.py:161} INFO - Started process (PID=50225) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:19:23.142+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:19:23.144+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:19:23.144+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:19:23.495+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:19:23.518+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:19:23.503+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:19:23.519+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:19:23.531+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.394 seconds
[2024-04-16T00:19:53.995+0000] {processor.py:161} INFO - Started process (PID=50294) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:19:53.998+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:19:54.001+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:19:54.001+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:19:54.459+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:19:54.507+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:19:54.472+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:19:54.509+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:19:54.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.535 seconds
[2024-04-16T00:20:24.686+0000] {processor.py:161} INFO - Started process (PID=50356) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:20:24.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:20:24.689+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:20:24.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:20:25.040+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:20:25.071+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:20:25.054+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:20:25.073+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:20:25.087+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.406 seconds
[2024-04-16T00:20:55.898+0000] {processor.py:161} INFO - Started process (PID=50416) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:20:55.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:20:55.913+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:20:55.912+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:20:56.425+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:20:56.445+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:20:56.435+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:20:56.446+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:20:56.462+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.568 seconds
[2024-04-16T00:21:26.597+0000] {processor.py:161} INFO - Started process (PID=50476) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:21:26.599+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:21:26.601+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:21:26.600+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:21:27.058+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:21:27.109+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:21:27.078+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:21:27.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:21:27.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.536 seconds
[2024-04-16T00:21:57.422+0000] {processor.py:161} INFO - Started process (PID=50536) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:21:57.423+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:21:57.425+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:21:57.425+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:21:57.854+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:21:57.874+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:21:57.863+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:21:57.875+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:21:57.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.470 seconds
[2024-04-16T00:22:28.579+0000] {processor.py:161} INFO - Started process (PID=50596) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:22:28.580+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:22:28.582+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:22:28.582+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:22:28.995+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:22:29.010+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:22:29.001+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:22:29.011+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:22:29.026+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.452 seconds
[2024-04-16T00:22:59.540+0000] {processor.py:161} INFO - Started process (PID=50655) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:22:59.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:22:59.551+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:22:59.550+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:22:59.948+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:22:59.963+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:22:59.954+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:22:59.964+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:22:59.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.439 seconds
[2024-04-16T00:23:30.099+0000] {processor.py:161} INFO - Started process (PID=50717) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:23:30.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:23:30.103+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:23:30.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:23:30.480+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:23:30.501+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:23:30.489+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:23:30.502+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:23:30.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.423 seconds
[2024-04-16T00:24:01.395+0000] {processor.py:161} INFO - Started process (PID=50778) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:24:01.396+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:24:01.399+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:24:01.399+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:24:01.922+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:24:01.945+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:24:01.933+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:24:01.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:24:01.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.578 seconds
[2024-04-16T00:24:32.686+0000] {processor.py:161} INFO - Started process (PID=50838) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:24:32.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:24:32.689+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:24:32.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:24:33.115+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:24:33.135+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:24:33.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:24:33.136+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:24:33.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.467 seconds
[2024-04-16T00:25:03.669+0000] {processor.py:161} INFO - Started process (PID=50898) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:25:03.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:25:03.680+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:25:03.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:25:04.160+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:25:04.180+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:25:04.169+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:25:04.181+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:25:04.194+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.529 seconds
[2024-04-16T00:25:34.406+0000] {processor.py:161} INFO - Started process (PID=50958) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:25:34.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:25:34.410+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:25:34.409+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:25:34.816+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:25:34.831+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:25:34.822+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:25:34.832+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:25:34.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.447 seconds
[2024-04-16T00:26:05.417+0000] {processor.py:161} INFO - Started process (PID=51018) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:26:05.418+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:26:05.420+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:26:05.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:26:05.835+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:26:05.890+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:26:05.875+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:26:05.891+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:26:05.906+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.495 seconds
[2024-04-16T00:26:36.273+0000] {processor.py:161} INFO - Started process (PID=51081) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:26:36.274+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:26:36.276+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:26:36.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:26:36.640+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:26:36.664+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:26:36.651+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:26:36.666+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:26:36.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.414 seconds
[2024-04-16T00:27:07.674+0000] {processor.py:161} INFO - Started process (PID=51142) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:27:07.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:27:07.682+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:27:07.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:27:08.294+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:27:08.313+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:27:08.304+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:27:08.314+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:27:08.340+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.671 seconds
[2024-04-16T00:27:38.735+0000] {processor.py:161} INFO - Started process (PID=51202) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:27:38.736+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:27:38.738+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:27:38.738+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:27:39.121+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:27:39.278+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:27:39.267+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:27:39.283+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:27:39.312+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.581 seconds
[2024-04-16T00:28:09.454+0000] {processor.py:161} INFO - Started process (PID=51262) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:28:09.456+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:28:09.457+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:28:09.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:28:09.893+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:28:09.913+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:28:09.899+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:28:09.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:28:09.940+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.491 seconds
[2024-04-16T00:28:40.087+0000] {processor.py:161} INFO - Started process (PID=51322) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:28:40.123+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:28:40.125+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:28:40.125+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:28:40.621+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:28:40.639+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:28:40.630+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:28:40.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:28:40.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.570 seconds
[2024-04-16T00:29:10.843+0000] {processor.py:161} INFO - Started process (PID=51382) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:29:10.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:29:10.902+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:29:10.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:29:11.416+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:29:11.431+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:29:11.425+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:29:11.432+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:29:11.444+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.605 seconds
[2024-04-16T00:29:41.558+0000] {processor.py:161} INFO - Started process (PID=51442) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:29:41.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:29:41.560+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:29:41.560+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:29:42.137+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:29:42.161+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:29:42.147+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:29:42.162+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:29:42.176+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.622 seconds
[2024-04-16T00:30:12.296+0000] {processor.py:161} INFO - Started process (PID=51504) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:30:12.297+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:30:12.298+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:30:12.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:30:13.113+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:30:13.127+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:30:13.122+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:30:13.128+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:30:13.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.848 seconds
[2024-04-16T00:30:43.751+0000] {processor.py:161} INFO - Started process (PID=51564) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:30:43.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:30:43.755+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:30:43.755+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:30:44.171+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:30:44.187+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:30:44.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:30:44.188+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:30:44.202+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.455 seconds
[2024-04-16T00:31:14.302+0000] {processor.py:161} INFO - Started process (PID=51624) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:31:14.303+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:31:14.305+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:31:14.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:31:14.655+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:31:14.678+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:31:14.659+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:31:14.679+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:31:14.694+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.396 seconds
[2024-04-16T00:31:44.877+0000] {processor.py:161} INFO - Started process (PID=51684) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:31:44.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:31:44.895+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:31:44.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:31:45.725+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:31:45.744+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:31:45.731+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:31:45.749+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:31:45.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.902 seconds
[2024-04-16T00:32:16.354+0000] {processor.py:161} INFO - Started process (PID=51745) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:32:16.356+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:32:16.357+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:32:16.357+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:32:16.737+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:32:16.768+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:32:16.756+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:32:16.769+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:32:16.782+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.432 seconds
[2024-04-16T00:32:47.690+0000] {processor.py:161} INFO - Started process (PID=51806) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:32:47.691+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:32:47.693+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:32:47.692+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:32:48.098+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:32:48.110+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:32:48.104+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:32:48.111+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:32:48.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.439 seconds
[2024-04-16T00:33:18.936+0000] {processor.py:161} INFO - Started process (PID=51865) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:33:18.937+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:33:18.939+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:33:18.939+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:33:19.319+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:33:19.340+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:33:19.329+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:33:19.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:33:19.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.421 seconds
[2024-04-16T00:56:22.389+0000] {processor.py:161} INFO - Started process (PID=41) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:56:22.391+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:56:22.394+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:56:22.394+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:56:23.465+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:56:23.477+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:56:23.471+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:56:23.478+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:56:23.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 1.109 seconds
[2024-04-16T00:56:53.620+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:56:53.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:56:53.625+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:56:53.625+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:56:53.954+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:56:53.968+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:56:53.961+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:56:53.969+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:56:53.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.362 seconds
[2024-04-16T00:57:24.394+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:57:24.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:57:24.396+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:57:24.395+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:57:24.751+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:57:24.774+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:57:24.763+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:57:24.775+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:57:24.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.396 seconds
[2024-04-16T00:57:55.050+0000] {processor.py:161} INFO - Started process (PID=230) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:57:55.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:57:55.053+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:57:55.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:57:55.415+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:57:55.431+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:57:55.420+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:57:55.432+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:57:55.443+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.397 seconds
[2024-04-16T00:58:25.563+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:58:25.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:58:25.565+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:58:25.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:58:25.942+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:58:25.953+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:58:25.947+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:58:25.955+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:58:25.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.406 seconds
[2024-04-16T00:58:56.488+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:58:56.489+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:58:56.490+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:58:56.490+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:58:56.830+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:58:56.849+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:58:56.841+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:58:56.850+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:58:56.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.376 seconds
[2024-04-16T00:59:26.927+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:59:26.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:59:26.929+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:59:26.929+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:59:27.309+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:59:27.319+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:59:27.313+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:59:27.320+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:59:27.330+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.407 seconds
[2024-04-16T00:59:58.101+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:59:58.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T00:59:58.105+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:59:58.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:59:58.551+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T00:59:58.563+0000] {logging_mixin.py:188} INFO - [2024-04-16T00:59:58.556+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T00:59:58.564+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T00:59:58.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.481 seconds
[2024-04-16T01:00:28.782+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:00:28.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:00:28.784+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:00:28.784+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:00:29.128+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:00:29.151+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:00:29.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:00:29.152+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:00:29.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.384 seconds
[2024-04-16T01:00:59.556+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:00:59.557+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:00:59.559+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:00:59.558+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:00:59.903+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:00:59.913+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:00:59.908+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:00:59.914+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:00:59.927+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.375 seconds
[2024-04-16T01:01:30.023+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:01:30.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:01:30.027+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:01:30.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:01:30.372+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:01:30.388+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:01:30.378+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:01:30.389+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:01:30.399+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.380 seconds
[2024-04-16T01:02:00.552+0000] {processor.py:161} INFO - Started process (PID=724) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:02:00.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:02:00.555+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:02:00.555+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:02:00.930+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:02:00.949+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:02:00.937+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:02:00.950+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:02:00.959+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.411 seconds
[2024-04-16T01:02:31.039+0000] {processor.py:161} INFO - Started process (PID=786) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:02:31.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:02:31.041+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:02:31.041+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:02:31.345+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:02:31.352+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:02:31.348+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:02:31.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:02:31.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.327 seconds
[2024-04-16T01:03:01.752+0000] {processor.py:161} INFO - Started process (PID=847) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:03:01.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:03:01.754+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:03:01.754+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:03:02.243+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:03:02.273+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:03:02.260+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:03:02.274+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:03:02.287+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.539 seconds
[2024-04-16T01:03:32.411+0000] {processor.py:161} INFO - Started process (PID=908) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:03:32.412+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:03:32.413+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:03:32.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:03:32.750+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:03:32.758+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:03:32.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'AAPL_daily_cleaned.csv'
[2024-04-16T01:03:32.759+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:03:32.771+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.363 seconds
[2024-04-16T01:04:03.192+0000] {processor.py:161} INFO - Started process (PID=968) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:04:03.211+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:04:03.213+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:04:03.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:04:03.647+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:04:03.720+0000] {logging_mixin.py:188} WARNING - /opt/airflow/dags/db_connection.py:17 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:04:03.755+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:04:03.756+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:04:03.739+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:04:03.757+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:04:03.772+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.585 seconds
[2024-04-16T01:04:34.562+0000] {processor.py:161} INFO - Started process (PID=1027) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:04:34.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:04:34.564+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:04:34.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:04:34.588+0000] {logging_mixin.py:188} WARNING - /opt/airflow/dags/data_cleaning_transformation.py:36 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:04:34.995+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'AAPL_daily_data.csv'
[2024-04-16T01:04:35.240+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:04:35.245+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:04:35.108+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:04:35.248+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:04:35.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.704 seconds
[2024-04-16T01:05:05.789+0000] {processor.py:161} INFO - Started process (PID=1087) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:05:05.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:05:05.791+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:05:05.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:05:05.820+0000] {logging_mixin.py:188} WARNING - /opt/airflow/dags/data_cleaning_transformation.py:35 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:05:05.821+0000] {logging_mixin.py:188} WARNING - /opt/airflow/dags/data_cleaning_transformation.py:36 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:05:06.130+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'dags\\AAPL_daily_data.csv'
[2024-04-16T01:05:06.143+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:05:06.143+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:05:06.137+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:05:06.144+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:05:06.154+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.369 seconds
[2024-04-16T01:06:13.275+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:06:13.276+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:06:13.277+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:06:13.277+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:06:14.320+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'dags\\AAPL_daily_data.csv'
[2024-04-16T01:06:14.337+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:06:14.338+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:06:14.327+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:06:14.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:06:14.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 1.081 seconds
[2024-04-16T01:06:44.558+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:06:44.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:06:44.561+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:06:44.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:06:44.876+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'dags\\AAPL_daily_data.csv'
[2024-04-16T01:06:44.898+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:06:44.899+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:06:44.887+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:06:44.900+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:06:44.911+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.357 seconds
[2024-04-16T01:07:14.999+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:07:15.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:07:15.002+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:07:15.002+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:07:15.341+0000] {logging_mixin.py:188} INFO - An error occurred during data cleaning and transformation: [Errno 2] No such file or directory: 'dags\\AAPL_daily_data.csv'
[2024-04-16T01:07:15.361+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:07:15.361+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:07:15.348+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:07:15.362+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:07:15.371+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.379 seconds
[2024-04-16T01:07:45.583+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:07:45.584+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:07:45.586+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:07:45.586+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:07:46.008+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:07:46.018+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:07:46.035+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:07:46.036+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:07:46.024+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:07:46.037+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:07:46.047+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.468 seconds
[2024-04-16T01:08:45.285+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:08:45.286+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:08:45.289+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:08:45.288+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:08:46.225+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:08:46.234+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:08:46.251+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:08:46.252+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:08:46.240+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:08:46.253+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:08:46.265+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.984 seconds
[2024-04-16T01:10:29.948+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:10:29.949+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:10:29.950+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:10:29.950+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:10:31.111+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:10:31.131+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:10:31.164+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:10:31.165+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:10:31.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:10:31.166+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:10:31.178+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 1.234 seconds
[2024-04-16T01:11:01.370+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:11:01.371+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:11:01.372+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:11:01.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:11:02.106+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:11:02.133+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:11:02.152+0000] {logging_mixin.py:188} WARNING - <unknown>:1 SyntaxWarning: invalid escape sequence '\A'
[2024-04-16T01:11:02.153+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:11:02.138+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 17, in <module>
    df = pd.read_csv('dags\AAPL_daily_cleaned.csv')  # Update the path to your cleaned CSV file
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 948, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 611, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1448, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/parsers/readers.py", line 1705, in _make_engine
    self.handles = get_handle(
                   ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/common.py", line 863, in get_handle
    handle = open(
             ^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'dags\\AAPL_daily_cleaned.csv'
[2024-04-16T01:11:02.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:11:02.169+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.804 seconds
[2024-04-16T01:11:32.752+0000] {processor.py:161} INFO - Started process (PID=173) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:11:32.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:11:32.754+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:11:32.754+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:11:33.142+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:11:33.146+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:11:33.188+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:11:33.198+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:11:33.189+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:11:33.200+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:11:33.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.464 seconds
[2024-04-16T01:12:40.959+0000] {processor.py:161} INFO - Started process (PID=42) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:12:40.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:12:40.961+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:12:40.961+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:12:42.059+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:12:42.067+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:12:42.076+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:12:42.084+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:12:42.077+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:12:42.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:12:42.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 1.145 seconds
[2024-04-16T01:13:12.136+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:13:12.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:13:12.139+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:13:12.138+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:13:12.487+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:13:12.492+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:13:12.497+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:13:12.501+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:13:12.498+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:13:12.504+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:13:12.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.383 seconds
[2024-04-16T01:13:43.315+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:13:43.318+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:13:43.351+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:13:43.350+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:13:43.861+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:13:43.868+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:13:43.881+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:13:43.889+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:13:43.882+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:13:43.892+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:13:43.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.590 seconds
[2024-04-16T01:14:14.643+0000] {processor.py:161} INFO - Started process (PID=234) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:14:14.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:14:14.645+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:14:14.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:14:15.042+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:14:15.048+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:14:15.056+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:14:15.064+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:14:15.057+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:14:15.066+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:14:15.077+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.438 seconds
[2024-04-16T01:14:45.182+0000] {processor.py:161} INFO - Started process (PID=299) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:14:45.183+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:14:45.185+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:14:45.185+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:14:45.512+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:14:45.516+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:14:45.521+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:14:45.526+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:14:45.521+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:14:45.527+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:14:45.536+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.358 seconds
[2024-04-16T01:15:16.666+0000] {processor.py:161} INFO - Started process (PID=359) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:15:16.667+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:15:16.680+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:15:16.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:15:17.206+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:15:17.211+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:15:17.216+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:15:17.221+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:15:17.217+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:15:17.223+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:15:17.234+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.574 seconds
[2024-04-16T01:15:48.102+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:15:48.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:15:48.104+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:15:48.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:15:48.635+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:15:48.641+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:15:48.652+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:15:48.689+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:15:48.655+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:15:48.697+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:15:48.711+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.615 seconds
[2024-04-16T01:16:19.492+0000] {processor.py:161} INFO - Started process (PID=483) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:16:19.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:16:19.494+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:16:19.493+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:16:19.840+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:16:19.859+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:16:19.934+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:16:20.015+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:16:19.953+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:16:20.018+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:16:20.034+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.546 seconds
[2024-04-16T01:16:50.185+0000] {processor.py:161} INFO - Started process (PID=546) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:16:50.186+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:16:50.188+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:16:50.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:16:50.575+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:16:50.582+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:16:50.589+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:16:50.596+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:16:50.589+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:16:50.598+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:16:50.607+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.425 seconds
[2024-04-16T01:17:20.700+0000] {processor.py:161} INFO - Started process (PID=603) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:17:20.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:17:20.704+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:17:20.704+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:17:21.076+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:17:21.083+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:17:21.091+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:17:21.099+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:17:21.091+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:17:21.101+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:17:21.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.417 seconds
[2024-04-16T01:17:51.227+0000] {processor.py:161} INFO - Started process (PID=664) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:17:51.229+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:17:51.231+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:17:51.231+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:17:51.692+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:17:51.698+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:17:51.708+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:17:51.716+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:17:51.709+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 6, in <module>
    import db_connection
  File "/opt/airflow/dags/db_connection.py", line 35, in <module>
    if conn is not None:
       ^^^^
NameError: name 'conn' is not defined
[2024-04-16T01:17:51.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:17:51.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.505 seconds
[2024-04-16T01:19:27.108+0000] {processor.py:161} INFO - Started process (PID=43) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:19:27.109+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:19:27.110+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:19:27.110+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:19:28.029+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:19:28.037+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:19:28.047+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:19:28.072+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:19:28.063+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:19:28.074+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:19:28.085+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.981 seconds
[2024-04-16T01:19:58.777+0000] {processor.py:161} INFO - Started process (PID=105) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:19:58.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:19:58.780+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:19:58.780+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:19:59.109+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:19:59.114+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:19:59.120+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:19:59.134+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:19:59.127+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:19:59.135+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:19:59.144+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.372 seconds
[2024-04-16T01:20:29.526+0000] {processor.py:161} INFO - Started process (PID=167) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:20:29.527+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:20:29.529+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:20:29.528+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:20:30.096+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:20:30.134+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:20:30.174+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:20:30.317+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:20:30.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:20:30.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:20:30.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.806 seconds
[2024-04-16T01:21:00.382+0000] {processor.py:161} INFO - Started process (PID=231) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:21:00.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:21:00.385+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:21:00.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:21:00.868+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:21:00.872+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:21:00.879+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:21:00.886+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:21:00.882+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:21:00.887+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:21:00.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.520 seconds
[2024-04-16T01:21:31.520+0000] {processor.py:161} INFO - Started process (PID=292) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:21:31.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:21:31.523+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:21:31.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:21:31.979+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:21:31.985+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:21:31.993+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:21:32.022+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:21:32.005+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:21:32.025+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:21:32.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.520 seconds
[2024-04-16T01:22:02.249+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:22:02.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:22:02.251+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:22:02.251+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:22:02.626+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:22:02.640+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:22:02.653+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:22:02.667+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:22:02.660+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:22:02.669+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:22:02.680+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.435 seconds
[2024-04-16T01:22:33.535+0000] {processor.py:161} INFO - Started process (PID=416) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:22:33.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:22:33.539+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:22:33.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:22:33.856+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:22:33.860+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:22:33.865+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:22:33.872+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:22:33.869+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:22:33.873+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:22:33.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.356 seconds
[2024-04-16T01:23:03.943+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:23:03.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:23:03.945+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:23:03.945+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:23:04.395+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:23:04.452+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:23:04.475+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:23:04.501+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:23:04.481+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:23:04.505+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:23:04.517+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.578 seconds
[2024-04-16T01:23:34.974+0000] {processor.py:161} INFO - Started process (PID=541) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:23:34.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:23:34.976+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:23:34.976+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:23:35.317+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:23:35.320+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:23:35.327+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:23:35.335+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:23:35.331+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:23:35.337+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:23:35.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.378 seconds
[2024-04-16T01:24:05.829+0000] {processor.py:161} INFO - Started process (PID=601) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:24:05.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:24:05.832+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:24:05.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:24:06.277+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:24:06.283+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:24:06.293+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:24:06.306+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:24:06.302+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:24:06.307+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:24:06.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.494 seconds
[2024-04-16T01:24:36.655+0000] {processor.py:161} INFO - Started process (PID=663) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:24:36.698+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:24:36.730+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:24:36.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:24:37.062+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:24:37.068+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:24:37.078+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:24:37.099+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:24:37.090+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:24:37.102+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:24:37.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.464 seconds
[2024-04-16T01:25:07.351+0000] {processor.py:161} INFO - Started process (PID=726) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:25:07.353+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:25:07.354+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:25:07.354+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:25:08.054+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:25:08.065+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:25:08.079+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:25:08.101+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:25:08.084+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:25:08.103+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:25:08.112+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.765 seconds
[2024-04-16T01:25:38.516+0000] {processor.py:161} INFO - Started process (PID=788) to work on /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:25:38.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/financial_data_pipeline.py for tasks to queue
[2024-04-16T01:25:38.520+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:25:38.519+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:25:38.924+0000] {logging_mixin.py:188} INFO - No missing values detected.
[2024-04-16T01:25:38.930+0000] {logging_mixin.py:188} INFO - Data cleaning and transformation completed successfully. Cleaned data saved to dags/AAPL_daily_cleaned.csv
[2024-04-16T01:25:38.937+0000] {logging_mixin.py:188} INFO - An error occurred: connection to server at "localhost" (127.0.0.1), port 5432 failed: Connection refused
	Is the server running on that host and accepting TCP/IP connections?
connection to server at "localhost" (::1), port 5432 failed: Cannot assign requested address
	Is the server running on that host and accepting TCP/IP connections?
[2024-04-16T01:25:38.945+0000] {logging_mixin.py:188} INFO - [2024-04-16T01:25:38.942+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/financial_data_pipeline.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 995, in exec_module
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "/opt/airflow/dags/financial_data_pipeline.py", line 7, in <module>
    import stock_price_analysis
  File "/opt/airflow/dags/stock_price_analysis.py", line 3, in <module>
    import matplotlib.pyplot as plt
ModuleNotFoundError: No module named 'matplotlib'
[2024-04-16T01:25:38.947+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/financial_data_pipeline.py
[2024-04-16T01:25:38.957+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/financial_data_pipeline.py took 0.446 seconds
